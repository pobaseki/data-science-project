{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPhZsyP1R9sz"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project description**\n",
        "\n",
        "**Abstract**\n",
        "\n",
        "Workplace safety has become a growing concern for many industries due to unsafe environments impacting productivity and resulting in loss of workers. Head injuries are one of the most common types of injuries workers suffer at workplace. Wearing safety helmets can reduce injuries to workers at construction sites, but due to various reasons, safety helmets are not always worn. Based on this need, we believe that a computer vision-based automatic safety helmet detection system is extremely important to detect if the worker is wearing a safety helmet or not.\n",
        "\n",
        "Our solution is intended for construction companies as construction entails high-risk operations that require workers to work in dangerous surroundings. Based on our internet search, we found that few companies have focused solutions for construction companies. Furthermore, many of the solutions failed in detecting safety helmets in complex scenarios, such as sites with multiple workers using sensors, machine learning and deep learning techniques. Therefore, our solution addresses complex scenarios using a deep learning (YOLO algorithm). We are using You Only Look Once (YOLOv7) one of the fastest real-time computer vision algorithms that surpasses all previous object detectors in terms of both speed and accuracy. For our project, we took dataset from Kaggle where we divided data in certain proportion for our training, testing and validation purpose. Our project results showed that the YOLOv7x architecture achieved the best mean average precision (mAP) of 95.9%, thereby showing excellent results in detecting safety helmets even in low-light condition. We believe that our solution can save not only companies regulatory enforcement cost but also the human lives.\n",
        "\n",
        "Introduction\n",
        "Construction is ranked one of the most dangerous industries to work in, with the highest reports of fatal work injuries. According to the U.S. Bureau of Labor Statistics, the number of fatalities has steadily climbed from 985 in 2015 to 1034 in 2020, with an annual increase of 2%. Over half a million workplace injuries being reported, with the construction industry being one of the highest contributors. Some developing nations have a substantially higher mortality rate than developed nations. Half of all fatalities from accidental falls and a considerable number of fatalities from slips, trips, and being struck by falling items may be reduced if employees wore hard helmets properly. Automatic helmet detection is basically an object detection problem and can be solved using deep learning and computer vision-based approaches. Two types of state-of-the-art deep learning methods for object detection are currently available:\n",
        "\n",
        "1.     The R-CNN (Convolutional Neural Network)-based target detection algorithm, which generates candidate regions ﬁrst and then performs classiﬁcation or regression.\n",
        "\n",
        "2.      The You Only Look Once [15,16] (YOLO) and Single Shot MultiBox Detector (SSD) algorithms, which perform classiﬁcation or regression using only one CNN.\n",
        "\n",
        "R-CNN-based approaches achieved relatively higher accuracy with the demerit of longer execution time, making them unsuitable for real-time scenarios. The SSD algorithm runs faster but faces problems in detecting small objects, which could be problematic in automatic helmet detection. We used YOLOv7 architectures automatically detect safety helmets at construction sites. YOLOv7 is the latest YOLO architecture, and has different models based on size. This project report describes the dataset, the methodology used for safety helmet detection, and the different test criteria for the methods.\n",
        "\n",
        "Business Problem\n",
        "Construction companies are facing 3 main business challenges:\n",
        "\n",
        "1.     Deal with high initial construction project cost\n",
        "\n",
        "Companies continue to experience the aftereffects of the pandemic, including a shortage of construction materials, high materials, and labor costs. Companies don’t put so much planning in enforcement of regulation as it adds cost to their bottom line. But companies failed to realize that US government has strictly enforced regulations via Occupational Safety and Health Act (OSHA)  and will cost companies in thousands or even millions besides losing reputation and deal with consequences of being non-compliant.\n",
        "\n",
        "2.     Construction workers choose not to wear helmets\n",
        "\n",
        "In year 2020 in an annual training program, the Environmental Health and Safety department of New York University (NYU) conducted a survey was conducted on thirty-three (33) construction companies in California to gain a better understanding of issues with PPE and reasons for non-compliance. The survey found that only 64% of construction workers always wear their PPE. Wearing of helmets causes worker’s stress in hot, sunny, confined, or poorly ventilated areas and it is uncomfortable. Other reasons such as anxiety and fit of PPE were also brought to light.\n",
        "\n",
        "3.     Challenge to perform real-time supervision\n",
        "\n",
        "Federal OSHA is a small agency, approx. 1850 inspectors responsible for the health and safety of 130 million workers employed at more than 8 million worksites around the nation. Only a small fraction of construction worksites is inspected every year. Wage differences and not adequate trainings have led to construction employees avoid PPE guidelines to keep them safe during work and exposing themselves to high risk of injury and death.\n",
        "\n",
        "Approach\n",
        "Many solutions have been implemented on safety helmet detection on construction sites based on sensor, machine learning, and deep learning techniques. Most of them failed in detecting safety helmets in complex scenarios, such as sites with multiple workers and detecting helmet in low-light conditions and with small object sizes. Our solution addresses both scenarios.\n",
        "\n",
        "We used You Only Look Once (YOLOv7) one of the fastest real-time computer vision algorithms to detect 3 classes – Helmet, Person, and Head. Yolov7 surpasses all previous object detectors in terms of both speed and accuracy in the range of 5 frame per second (FPS) to 160 frames per second (FPS) .\n",
        "\n",
        "Our dataset is downloaded from Kaggle containing 5000 images of hard hats with bounding box annotation in the PASCAL VOC format. We used Google Collab, a product from Google Research and well suited for deep learning, to write and execute our python code. Following are our high-level approach to implement and test model:\n",
        "\n",
        "§  Download the dataset which required a key file (Kaggle.json) for authentication before downloading\n",
        "\n",
        "§  Download Yolov7 and dependencies\n",
        "\n",
        "§  Perform EDA on the dataset – images analysis and annotation analysis\n",
        "\n",
        "§  Perform data preprocessing such as mapping class names to ids, normalize the co-ordinates by the dimensions of the image and perform annotation conversion from PASCAL VOC format to Yolo\n",
        "\n",
        "§  Setup the directories for training, testing and evaluation by splitting the dataset\n",
        "\n",
        "§  Setup the Yaml files or training\n",
        "\n",
        "§  Train the model\n",
        "\n",
        "§  Run inference on test images and videos\n",
        "\n",
        "References\n",
        "1.     For Yolov7 resources, https://github.com/WongKinYiu/yolov7.git\n",
        "\n",
        "@article {wang2022yolov7, title={{YOLOv7}: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors}, author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark}, journal={arXiv preprint arXiv:2207.02696}, year={2022}\n",
        "\n",
        "\n",
        "\n",
        "2.     Steven Smiley:  https://github.com/stevensmiley1989/Full_Loop_YOLO by Steven Smiley 2022/11/24\n",
        "\n",
        "\n",
        "\n",
        "3.     Pavlov, I., Jung, C., & Freud, S. (year of last update, month day). Webpage title. Source or hosting webpage. https://www.someurl.com/full/address\n",
        "\n",
        "4.     Ramirez, A. T. (year). Book title. Publisher. https://doi.org/10.xx.xxxxxxxxxx\n",
        "\n"
      ],
      "metadata": {
        "id": "M1xeeZhlSIUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prerequisites\n",
        "Dataset: In this Project use open-source safety helmet dataset (https://www.kaggle.com/datasets/whenamancodes/helmet-detection-at-work-for-safety/data?select=images) available on Kaggle comprising of 5000 images with bounding box annotations in the PASCAL VOC format. The Kaggle image dataset consists of 5000 images containing three classes - \"Helmet\", “Person” and \"Head\" (focus on helmet ) classes will be used. The labeling method is defined as one not wearing a helmet termed as ‘person’, the ‘head’ as a labeled and the ‘helmet’. The label file of each picture is in xml file format which can be read from the figure. Each image size is 416x415, the picture has three bounding boxes, head, helmet and person where the coordinate of the head, helmet and person is provided.\n",
        "\n",
        "This is split into training (60%), testing (20%), and validation (20%) sets."
      ],
      "metadata": {
        "id": "TpCxV88WSoYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nbh3lXeSxCX",
        "outputId": "a2fb4bd1-7433-4933-fea0-d407c595b57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone YOLOv7 repository\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7\n",
        "\n",
        "# Install required packages\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGU3UfK_dR0b",
        "outputId": "1be22943-24fc-4c53-9cc4-32579fb8c40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov7' already exists and is not an empty directory.\n",
            "/content/yolov7\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.5)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.17.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.13.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2024.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2024.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "data_path = '/content/Helmet Detection.zip'\n",
        "images_path = os.path.join(data_path, 'images')\n",
        "annotations_path = os.path.join(data_path, 'annotations')\n",
        "\n",
        "# Move images and annotations to YOLOv7 directory\n",
        "if not os.path.exists('data/images'):\n",
        "    shutil.copytree(images_path, 'data/images')\n",
        "if not os.path.exists('data/annotations'):\n",
        "    shutil.copytree(annotations_path, 'data/annotations')\n"
      ],
      "metadata": {
        "id": "na-HE38GdRgZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5961cff4-d5d9-4c3d-add1-69304c3f9cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Helmet Detection.zip/images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ade02f43dd22>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Move images and annotations to YOLOv7 directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/annotations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/annotations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \"\"\"\n\u001b[1;32m    556\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shutil.copytree\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Helmet Detection.zip/images'"
          ]
        }
      ]
    }
  ]
}
